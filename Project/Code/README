			| GENERAL GUIDELINES:
			|
         ,....,		| 	IN ORDER TO CREATE ANY AGENT, WE FOLLOW THE AGENT.PY INTERFACE	
      ,::::::<		| 
     ,::/^\"``.		| 	THE AGENTS DYNAMIC TOGETHER IS IN THE FILE AGENTSPLAYGROUND.PY			
    ,::/, `   e`.	|			
   ,::; |        '.	|	USE PIECELISTs FOR YOUR BOARD, AVALIABLE IN THE STATEREPRESENTATIONS FOLDER
   ,::|  \___,-.  c)	| 	
   ;::|     \   '-'	|
   ;::|      \		| WHERE TO START?	
   ;::|   _.=`\		|	ONE EXAMPLE IS ALREADY THERE: THE HORSES.PY. 
   `;:|.=` _.=`\	|	
     '|_.=`   __\	|	MAINLY, WHAT YOU WANT TO DO IS TO CREATE AN AGENT THAT OBEYS THE AGENT INTERFACE. AFTER YOU'RE DONE,
     `\_..==`` /	|	TELL THE TEAM SO THEY CAN PUT YOUR AGENT WORKING TOGETHER WITH THE OTHERS
      .'.___.-'.	|
     /          \	|	
    ('--......--')	| WHAT ! NOT ! TO DO
    /'--......--'\	|	
    `"--......--"	|	DO NOT TOUCH EITHER THE INTERFACE OR THE PLAY GROUND WITHOUT TRIPLE CHECKING. OTHERWISE
			|	YOU MIGHT BREAK EVERYONE'S CODE
			|
			|	

CAREFUL WITH THESE:

	DON'T MAINTAIN STATE OF YOUR PIECES IN YOUR CLASS (UNLESS VERY SPECIFIC CASES). 
	THIS BECAUSE, IMAGINE THE AGENTS OF PAWNS, THE PAWN NUMBER 1 CAN BE THE PAWN NUMBER 2 OR 3
	IN THE NEXT ITERATION. THIS HAPPENS BECAUSE THE NUMBER OF THE PAWN IN THE STATE LIST HAS TO 
	DO WITH ITS CURRENT POSITION (SEE PIECELIST)

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
			TO DO LIST / PLAN
				
		
WE'RE CURRENTLY HERE----->	1) DESIGN AGENTS
					HORSES (TO), BISHOPS (DR), ROOKS (RA), QUEEN (DF), KING, PAWNS 
				
2ª e 3ª feira---->		2) TAKE CARE OF MASSIVE AGENT LEARNING
					Which parameters to use on the network?
					Massive generation of Samples (and hours and hours to train NN).
					
4ª feira --->			3) EVALUATE OUR SYSTEM.
					did it overfit?
					is it better than random?
					is it better than stockfish?
					if it isn't, how much better than random vs stockfish it is?
					(...)
					
				/////////  ADVANCED CONTENT - If we have time //////////	
					
5ª e 6ª ---->			4) DO EVALUATION FUNCTION (King's centralized decision)
				
				5) DO REINFORCMENT LEARNING 
5ª e 6ª --->					Our agents against our agents
					Evaluate if RL did inmprove the agents
					
				//////////  In The End  ////////////
				
					    RELATÓRIO!
			
				
	
////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

NOISE CANCELLATION:
	BECAUSE WE CHANGED A LOT OF RULES, THE STOCKFISH WILL PRODUCE MASSIVE AMOUNTS OF NOISE.
	TO CANCEL THIS YOU NEED TO GO TO: ~/.local/lib/python3.6/site-packages/chess/engine.py and 
	comment the line "LOGGER.exception("engine sent invalid ponder move")"
	YOU ALSO NEED TO WRITE "pass" because python doesn't allow empy "excepts"

	except ValueError:
		pass
		#LOGGER.exception("engine sent invalid ponder move")		


///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
SECOND PHASE:
	our goal is to train every agent.

Use the 150000 Game Samples to train your agent. Use horses as an Example, but, in specific, here's what you have to do:
	-There's some new methods you have to create: createValidationSet, model_builder, run_tuner, load_network_tuner
	IN DETAIL:
		createValidationSet: creates self.valid_x and self.valid_y which is 20% of all samples in your agent. 
				    Make sure to alter the __init__, now it's different (look at horse's)
		
		model_builder: First instal keras-tuner by running pip3 install keras-tuner.
			 	model_builder is so that the parameters can be chosen for you.
				It will create a keras-tuner model which says which parameters you want to vary.
				(PLEASE DON'T JUST COPY HORSE'S. CHANGE A THING OR TWO LIKE THE NUMBER OF LAYERS OR SO...)

		run_tuner:  After creating the model you want to vary, this function will vary them all and choose the best NN found.
			    It will then run a normal fit method so that your neural network can adapt to the samples

		load_network_tuner: After running the run_tuner, you should save your network with "serializeWeights". Now, you might
				think to get those weights back you only need to use the old function "loadWeights", but you can't. Because
				"loadWeights" will expect a NeuralNetwork with the shape of the one you built under "build_compile_model", but
				the model_builder & run_tuner changed it. So, load_network_tuner should be used after serializing weights that were achieved
				by model_builder and run_tuner.


	EASY SUMMARY:
		-DO HYPERAMETERIZATON
		-TEST WITH ONLY YOUR AGENT, COMMENT OBSERVED BEHAVIOUR

	AFTER ALL AGENTS ARE DONE:
		-TEST WITH ALL AGENTS


Here's what each one is doing:
	TO: Horses and King's decison and some general coding to be able to test.
			-> IF YOU WISH TO TEST YOUR CODE AND TO HASN'T SUBMITTED THAT PART, TALK TO HIM.
	PESTANA: Pawns and Rooks
	FARIA: Queen
	RAMALHO: Bishops

	Faria or Ramalho should do the King. It should be Ramalho, because Faria did two pieces in the first Phase.


PLEASE TRY YOUR BEST TO FINISH THIS UNTIL THE END OF WEDNESDAY. THIS MEANS WRITING THE SCRATCH OF THE REPORT OF EACH PIECE YOU'RE ATTRIBUTED.
THURSDAY (WE FINISH ALL THE REPORT). 

ANY DELAYS SHOULD BE COMMUNICATED.



	
					
				

